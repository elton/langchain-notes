{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I/O\n",
    "\n",
    "任何语言模型应用程序的核心元素都是模型。 LangChain 为您提供了与任何语言模型交互的构建块。 \n",
    "* 提示(Prompts)：模板化、动态选择和管理模型输入 \n",
    "* 语言模型(Language models)：通过通用接口调用语言模型 \n",
    "* 输出解析器(Output parsers)：从模型输出中提取信息\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://python.langchain.com/assets/images/model_io-1f23a36233d7731e93576d6885da2750.jpg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "编程模型的新方法是通过提示(Prompt)。提示(Prompt)是指模型的输入。此输入通常由多个组件构成。 LangChain 提供了几个类和函数来简化提示的构建和使用。 \n",
    "* 提示(Prompt)模板：参数化模型输入 \n",
    "* 示例选择器：动态选择要包含在提示中的示例\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/\\nYou are a naming consultant for new companies.\\nWhat is a good name for a company that makes colorful socks?\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"/\n",
    "You are a naming consultant for new companies.\n",
    "What is a good name for a company that makes {product}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# An example prompt with no input variables\n",
    "no_input_prompt = PromptTemplate(input_variables=[],\n",
    "                                 template=\"Tell me a joke.\")\n",
    "no_input_prompt.format()\n",
    "# -> \"Tell me a joke.\"\n",
    "\n",
    "# An example prompt with one input variable\n",
    "one_input_prompt = PromptTemplate(input_variables=[\"adjective\"],\n",
    "                                  template=\"Tell me a {adjective} joke.\")\n",
    "one_input_prompt.format(adjective=\"funny\")\n",
    "# -> \"Tell me a funny joke.\"\n",
    "\n",
    "# An example prompt with multiple input variables\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}.\")\n",
    "multiple_input_prompt.format(adjective=\"funny\", content=\"chickens\")\n",
    "# -> \"Tell me a funny joke about chickens.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 如果您不想手动指定 input_variables，您也​​可以使用 from_template 类方法创建一个 PromptTemplate。 langchain 会根据传递的模板自动推断 input_variables。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (AIMessage, HumanMessage, SystemMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}),\n",
       " HumanMessage(content='I love programming.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt])\n",
    "\n",
    "# get a chat completion from the formatted messages\n",
    "chat_prompt.format_prompt(input_language=\"English\",\n",
    "                          output_language=\"French\",\n",
    "                          text=\"I love programming.\").to_messages()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to a Feature Store\n",
    "\n",
    "特征存储是传统机器学习的一个概念，它确保输入模型的数据是最新的和相关的。有关更多信息，请参见此处。 \n",
    "\n",
    "在考虑将 LLM 应用程序投入生产时，这个概念非常重要。为了个性化 LLM 应用程序，您可能希望将 LLM 与有关特定用户的最新信息结合起来。特征存储是保持数据最新的好方法，LangChain 提供了一种将该数据与 LLM 结合的简单方法。 \n",
    "\n",
    "在此笔记本中，我们将展示如何将提示模板连接到特征存储。基本思想是从提示模板内部调用特征存储来检索值，然后将这些值格式化为提示。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feast\n",
    "\n",
    "首先，我们将使用流行的开源特征存储框架 [Feast](https://github.com/feast-dev/feast)。 \n",
    "\n",
    "这假设您已经运行了 README 中关于入门的步骤。我们将在入门部分构建该示例，并创建和 LLMChain 以向特定驱动程序写入有关其最新统计数据的注释。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   driver_id           event_timestamp  conv_rate  acc_rate  avg_daily_trips\n",
      "0       1001 2021-04-12 10:59:42+00:00   0.960894  0.269126              916\n",
      "1       1002 2021-04-12 08:12:10+00:00   0.563219  0.632244              981\n",
      "2       1003 2021-04-12 16:40:26+00:00   0.933522  0.890652               13\n",
      "3       1004 2021-04-12 15:01:12+00:00   0.243195  0.410256              254\n"
     ]
    }
   ],
   "source": [
    "from feast import FeatureStore\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "entity_df = pd.DataFrame.from_dict({\n",
    "    \"driver_id\": [1001, 1002, 1003, 1004],\n",
    "    \"event_timestamp\": [\n",
    "        datetime(2021, 4, 12, 10, 59, 42),\n",
    "        datetime(2021, 4, 12, 8, 12, 10),\n",
    "        datetime(2021, 4, 12, 16, 40, 26),\n",
    "        datetime(2021, 4, 12, 15, 1, 12)\n",
    "    ]\n",
    "})\n",
    "\n",
    "store = FeatureStore(repo_path=\"../my_feature_repo/feature_repo\")\n",
    "\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        'driver_hourly_stats:conv_rate', 'driver_hourly_stats:acc_rate',\n",
    "        'driver_hourly_stats:avg_daily_trips'\n",
    "    ],\n",
    ").to_df()\n",
    "\n",
    "print(training_df.head())\n",
    "\n",
    "# Train model\n",
    "# model = ml.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
