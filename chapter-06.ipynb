{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc8303b-3db7-4860-9e3e-c60c6ed551bc",
   "metadata": {},
   "source": [
    "# LangChain: Agents\n",
    "\n",
    "Agents use an LLM to determine which actions to take and in what order. \n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Using built in LangChain tools: DuckDuckGo search and Wikipedia\n",
    "* Defining your own tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4e0e8-c1d8-45ac-bb56-f1bccf2ae52e",
   "metadata": {},
   "source": [
    "## Built-in LangChain tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a193e4-8264-405e-ba41-8be9e2a61661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37800c55-7c15-44e8-b045-a44a7749de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737122e0-e511-4989-984f-369114626d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84329136-3a6e-48dd-9edf-ddcd185559ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ee3cd5-62e0-41a0-a019-d956578eb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88514caf-6c1a-4f58-adb3-0ec5ead8738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: We need to calculate 25% of 300, which involves multiplication and division.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"300*0.25\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 75.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe have the answer to the question.\n",
      "\n",
      "Final Answer: 75.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'75.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df3de0-7e18-4fbb-a93d-e109a156f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "agent.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eea6873-c2b4-4886-a3eb-2e5e1e59c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30059380-956a-4291-a826-52af8b60e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db22e14-9c06-4d55-a273-e40dccb46f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17f98f03-9cc8-462a-9145-d35d04aad701",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a94d03-a222-432c-a686-53e62e4fe770",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7f70d8-a5f4-4f10-a335-337ad0507d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to find out Leo DiCaprio's girlfriend's name and her age.\n",
      "Action: Search\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLeonardo DiCaprio has split from girlfriend Camila Morrone. Getty. Taking a look at his dating history, Leo has always had a preference for ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find out Camila Morrone's age.\n",
      "Action: Search\n",
      "Action Input: \"Camila Morrone age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m25 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to calculate her age raised to the 0.43 power.\n",
      "Action: Calculator\n",
      "Action Input: 25^(0.43)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3.991298452658078\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 3.991298452658078\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.991298452658078'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2e43a81-ded1-45bb-989c-047834c18be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to use the Search tool to find the weather in Shanghai today.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"Shanghai weather today\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTOMORROW'S WEATHER FORECAST. 6/14. 88°/ 72°. RealFeel® Sun 94 ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to refine my search query to get the weather for today in Shanghai.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"Shanghai weather today\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTOMORROW'S WEATHER FORECAST. 6/14. 88°/ 72°. RealFeel® Sun 94 ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to try a different search engine to get the weather for today in Shanghai.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"Shanghai weather today Baidu\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSun. Today · 93 °F · 4 mph. - ; Mon. Tomorrow · 94 °F · 5 mph. - ; Tue. 6-13 · 89 °F · 3 mph. 0-0.4\".\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found that the temperature in Shanghai today is 93°F and the wind speed is 4 mph.\n",
      "Final Answer: The temperature in Shanghai today is 93°F and the wind speed is 4 mph.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent.run(\"今天上海的天气如何？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4d99e94-56a0-40ee-89b6-ab927a993dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The temperature in Shanghai today is 93°F and the wind speed is 4 mph.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff9010-c2d5-4efb-8b21-77f9e4f95c5c",
   "metadata": {},
   "source": [
    "## Python Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860cca00-7423-4c7f-83ce-a6cbe533d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d58199-6ab9-4ad8-bc6b-b1e8cfb02a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4472d0db-7676-4364-a44b-54aa49590ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0af199c0-0973-49c7-9761-99da02bebf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI can use the sorted() function to sort the list of customers by last name and then first name. I will need to provide a key function to sorted() that returns a tuple of the last name and first name in that order.\n",
      "Action: Python REPL\n",
      "Action Input:\n",
      "```\n",
      "customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\n",
      "sorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\n",
      "print(sorted_customers)\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe customers are now sorted by last name and then first name.\n",
      "Final Answer: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a6c9df-34bc-4852-ba10-1c5aeab1a5f5",
   "metadata": {},
   "source": [
    "## Define your own tool\n",
    "\n",
    "the Tool consists of several components:\n",
    "\n",
    "- name (str), is required and must be unique within a set of tools provided to an agent\n",
    "\n",
    "- description (str), is optional but recommended, as it is used by an agent to determine tool use\n",
    "\n",
    "- return_direct (bool), defaults to False\n",
    "\n",
    "- args_schema (Pydantic BaseModel), is optional but recommended, can be used to provide more information (e.g., few-shot examples) or validation for expected parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9b950b3-4696-4f61-bfa8-7bada51d231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: DateTime in /opt/homebrew/lib/python3.10/site-packages (5.1)\n",
      "Requirement already satisfied: zope.interface in /opt/homebrew/lib/python3.10/site-packages (from DateTime) (6.0)\n",
      "Requirement already satisfied: pytz in /opt/homebrew/lib/python3.10/site-packages (from DateTime) (2023.3)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.10/site-packages (from zope.interface->DateTime) (67.6.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4a7cf49-5bd7-4fb7-8896-ae502311f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "240a1ade-7a21-4338-bc71-ca957b15f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8dcc8fe-9cc7-4280-b8b9-d34511da27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea341f0a-d70c-437a-8292-8b32e5618066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: We can use the `time` tool to get today's date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2023-06-13\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe answer to the question \"what's the date today?\" is 2023-06-13.\n",
      "Final Answer: 2023-06-13.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37d5bae5-1703-4e0f-959f-694a9a98ad53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ae62f546c24916880bc28777608ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ain/tool_config.json:   0%|          | 0.00/337 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4c0b819cc4491b91d571853466b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)n/model_downloads.py:   0%|          | 0.00/621 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/spaces/lysandre/hf-model-downloads:\n",
      "- model_downloads.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_download_counter: This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub. It takes the name of the category (such as text-classification, depth-estimation, etc), and returns the name of the checkpoint\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_huggingface_tool\n",
    "\n",
    "tool = load_huggingface_tool(\"lysandre/hf-model-downloads\")\n",
    "\n",
    "print(f\"{tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45050637-69d3-4060-adc5-41bc5e4391b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'facebook/bart-large-mnli'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"text-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb44902-b1b4-4c21-83a5-4fc9b9f286e2",
   "metadata": {},
   "source": [
    "### Define customer tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc03b34d-006a-42de-9d4f-39e54627db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19191c3d-c2fa-4b24-b6e1-c8b213ed5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcaf49c7-8ad2-4e60-97fa-150143d0a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:50: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the tool configs that are needed.\n",
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name = \"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efcb6e79-23bb-40a2-89ca-fe4defd7a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    question: str = Field()\n",
    "        \n",
    "\n",
    "tools.append(\n",
    "    Tool.from_function(\n",
    "        func=llm_math_chain.run,\n",
    "        name=\"Calculator\",\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "        args_schema=CalculatorInput\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9de405fb-8db5-4e50-b2f4-8408303012f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adaaf02e-d867-44a0-ace4-5ba697fa3a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to find out Leo DiCaprio's girlfriend's name and her age\n",
      "Action: Search\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLeonardo DiCaprio has split from girlfriend Camila Morrone. Getty. Taking a look at his dating history, Leo has always had a preference for ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI still need to find out her age\n",
      "Action: Search\n",
      "Action Input: \"Camila Morrone age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m25 years\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to calculate her age raised to the 0.43 power\n",
      "Action: Calculator\n",
      "Action Input: 25^0.43\u001b[0m25^0.43\u001b[32;1m\u001b[1;3m```text\n",
      "25**0.43\n",
      "```\n",
      "...numexpr.evaluate(\"25**0.43\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m3.991298452658078\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3.991298452658078\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 3.991298452658078\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.991298452658078'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e460b-c2d7-4177-b541-c6135d31b32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
