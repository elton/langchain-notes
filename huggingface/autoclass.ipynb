{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8924c04c-566d-4422-a59a-25bd7190fab4",
   "metadata": {},
   "source": [
    "# AutoClass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a3602-53a1-4146-b443-6afbc0f762e8",
   "metadata": {},
   "source": [
    "## AutoTokenizer\n",
    "\n",
    "AutoTokenizer(分词器)负责将文本预处理为数字数组，作为模型的输入。有多个规则管理标记化过程，包括如何拆分单词以及应在什么级别拆分单词（在[标记器摘要](https://huggingface.co/docs/transformers/tokenizer_summary)中了解有关标记化的更多信息）。最重要的是要记住，您需要使用**相同的模型名称**实例化分词器，以确保您使用的是与预训练模型相同的分词规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd004b6-ac40-454a-9705-428a476f5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f568f3b1-63e4-470c-9e3f-731ac67a069d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encode = tokenizer(\"We are very happy to show you the 🤗 Transformers library.\")\n",
    "print(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734eab02-63ec-4020-820f-38a3c491621f",
   "metadata": {},
   "source": [
    "- input_ids：你的token的数字表示。\n",
    "- attention_mask：指示应注意哪些token。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8225747a-296f-4edc-b712-e6d114e2da2d",
   "metadata": {},
   "source": [
    "AutoTokenizer(分词器)还可以接受输入列表，并填充和截断文本以返回具有统一长度的批次:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb65a1e4-0ed9-44bd-9eb8-d1caae71d61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n",
       "         58263, 13299,   119,   102],\n",
       "        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n",
       "           102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "pt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e2e54-9f5f-492d-86a7-8cf3a05def37",
   "metadata": {},
   "source": [
    "## AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d4c5ec-852b-43c1-ae40-024782aec1df",
   "metadata": {},
   "source": [
    "Transformers 提供了一种简单而统一的方式来加载预训练实例。这意味着您可以像加载 AutoTokenizer 一样加载 AutoModel。唯一的区别是为任务选择正确的[AutoModel](https://huggingface.co/docs/transformers/v4.30.0/en/model_doc/auto#transformers.AutoModel)。对于文本（或序列）分类，您应该加载 AutoModelForSequenceClassification："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2e959a-5d1c-4ad9-946e-e1531d995ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0e0ce2-1849-4c36-940b-a90b6bb78527",
   "metadata": {},
   "source": [
    "现在将经过预处理的一批输入直接传递给模型。你只需要通过添加 ** 来解压字典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97755061-da65-40df-b36a-4a1f50afbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_outputs = pt_model(**pt_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b3a717-375d-4d6e-b9b8-1ce1f56a07dc",
   "metadata": {},
   "source": [
    "该模型在logits属性中输出最终的激活值。对logits应用softmax函数来检索概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7754ca-0763-40df-bbca-6653618cb57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d2ec3-9ac9-41c7-9938-bcc02b8e3eda",
   "metadata": {},
   "source": [
    "`nlptown/bert-base-multilingual-uncased-sentiment` 这是一个基于Bert-base的多语言无损检测模型，用于对六种语言的产品评论进行情感分析的微调： 英语、荷兰语、德语、法语、西班牙语和意大利语。它以星星的数量（1到5之间）预测评论的情绪。该模型旨在直接用作上述六种语言的产品评论的情感分析模型，或用于相关情感分析任务的进一步微调。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
